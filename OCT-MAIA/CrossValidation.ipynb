{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289360c8",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "Cross validation is essential for this task but we have some problems to implement it: Since our data for a single patient are highly correlated we can only have them all either in the train or in the test set.\n",
    "For this reason we implement Cross validation without shuffling, and we also cannot use stratified CV.\n",
    "What we do, since our dataset is unbalance is to split into folds where we are sure that all data of a patient is in the same fold. Then we upsample train set test on the other and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d35404",
   "metadata": {},
   "source": [
    "# For this first part we are doing it only for Control patients, then we generalize by mixing control and AMD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af27a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\line\\Desktop\\Mauro\\2_Preprocessing_Code\\amd\\prl\\dataset.py:8: FutureWarning: The `skimage.morphology.selem` module is deprecated and will be removed in scikit-image 1.0 (`skimage.morphology.selem` has been moved to `skimage.morphology.footprints`).\n",
      "  from skimage.morphology import selem\n"
     ]
    }
   ],
   "source": [
    "from buildDataset import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "root_path =      DATAPATHS[\"preprocessed\"]\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,ConfusionMatrixDisplay,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274f6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129024, 80)\n",
      "(129024,)\n",
      "118272\n"
     ]
    }
   ],
   "source": [
    "basepath = r'C:\\Users\\line\\Desktop\\Mauro\\3_DataSet\\OCT_balanced'\n",
    "paths = glob.glob(os.path.join(basepath,'controlP' + '\\*.pickle'))\n",
    "X,y = getXYdata(paths, mode = 'raw',rootpath = basepath,normmode = 'EQ-hist')\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(768*14*11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f7d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6679716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold number: 7\n",
      "[ 32256  32257  32258 ... 129021 129022 129023]\n",
      "[    0     1     2 ... 32253 32254 32255]\n",
      "fold number: 8\n",
      "[     0      1      2 ... 129021 129022 129023]\n",
      "[32256 32257 32258 ... 64509 64510 64511]\n",
      "fold number: 9\n",
      "[     0      1      2 ... 129021 129022 129023]\n",
      "[64512 64513 64514 ... 96765 96766 96767]\n",
      "fold number: 10\n",
      "[    0     1     2 ... 96765 96766 96767]\n",
      "[ 96768  96769  96770 ... 129021 129022 129023]\n"
     ]
    }
   ],
   "source": [
    "fold_number = 6\n",
    "for tridx,tstidx in kf.split(X,y):\n",
    "    fold_number += 1\n",
    "    print(f'fold number: {fold_number}' )\n",
    "    print(tridx)\n",
    "    print(tstidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b87460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cv that specifies the folds of my dataset, basically to avoid shuffling\n",
    "# Having 12 control patients, splits should be divisors of 12, eg: 2 fold, 3-fold, 4-fold, 6-fold, 12-fold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def score_model(model,X,y, params = None, cv=None,plotMatrix = None):\n",
    "    \"\"\"\n",
    "    Creates folds manually, and upsamples within each fold.\n",
    "    Returns an array of validation (recall) scores\n",
    "    \"\"\"\n",
    "    #smoter = SMOTE(random_state=42)\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for train_fold_index, val_fold_index in cv.split(X, y):\n",
    "        # Get the training data\n",
    "        X_train_fold, y_train_fold = X[train_fold_index], y[train_fold_index]\n",
    "        # Get the validation data\n",
    "        X_val_fold, y_val_fold = X[val_fold_index], y[val_fold_index]\n",
    "\n",
    "        # Upsample only the data in the training section\n",
    "        #X_train_fold_upsample, y_train_fold_upsample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
    "        X_train_fold_upsample, y_train_fold_upsample = upsample(X_train_fold,y_train_fold)                                                                   \n",
    "        # Fit the model on the upsampled training data\n",
    "        if params:\n",
    "            model_obj = model(**params).fit(X_train_fold_upsample, y_train_fold_upsample)\n",
    "        else:\n",
    "            model_obj = model().fit(X_train_fold_upsample, y_train_fold_upsample)\n",
    "        if(plotMatrix):\n",
    "            # Display confusion matrix\n",
    "            ConfusionMatrixDisplay.from_estimator(model_obj, X_val_fold, y_val_fold)\n",
    "            plt.show()\n",
    "        \n",
    "        # Score the model on the (non-upsampled) validation data\n",
    "        predictions = model_obj.predict(X_val_fold)\n",
    "        scores.append(recall_score(y_val_fold, predictions))\n",
    "        scores.append(precision_score(y_val_fold, predictions))\n",
    "        scores.append(accuracy_score(y_val_fold, predictions))\n",
    "        scores.append(f1_score(y_val_fold, predictions))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7871f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = getXYdata(paths, mode = 'raw',rootpath = basepath,normmode = 'EQ-hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b08435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the recall scores: [0.20111576 0.99893843 0.99199014 1.         0.90127898 0.69791667]\n",
      "Here are the precisions scores: [0.25805297 0.15693796 0.34705756 0.31761387 0.44671157 0.3755004 ]\n",
      "Here are the accuracies scores: [0.77041481 0.76488095 0.85853795 0.84254092 0.85863095 0.86286272]\n",
      "Here are the f1 scores: [0.22605424 0.27125973 0.51421271 0.48210462 0.59735099 0.48828735]\n"
     ]
    }
   ],
   "source": [
    "# Example of the model in action\n",
    "kf = KFold(n_splits=6, shuffle=False)\n",
    "\n",
    "scores = score_model(GaussianNB,X,y, cv=kf)\n",
    "print(f'Here are the recall scores: {scores[::4]}')\n",
    "print(f'Here are the precisions scores: {scores[1::4]}')\n",
    "print(f'Here are the accuracies scores: {scores[2::4]}')\n",
    "print(f'Here are the f1 scores: {scores[3::4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e67c6",
   "metadata": {},
   "source": [
    "# Here we generalize to both AMD and CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb25f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = r'C:\\Users\\line\\Desktop\\Mauro\\3_DataSet\\OCT_balanced'\n",
    "paths = glob.glob(os.path.join(basepath,'controlP' + '\\*.pickle'))\n",
    "paths2 = glob.glob(os.path.join(basepath,'amdP' + '\\*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2603ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\0.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\10.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\0.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\11.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\12.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\1.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\2.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\3.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\2.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\4.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\5.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\3.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\6.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\7.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\5.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\8.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\controlP\\\\9.pickle', 'C:\\\\Users\\\\line\\\\Desktop\\\\Mauro\\\\3_DataSet\\\\OCT_balanced\\\\amdP\\\\6.pickle']\n"
     ]
    }
   ],
   "source": [
    "merged = [[paths[2*i],paths[2*i+1],paths2[i]]  for i in range(len(paths2))]\n",
    "flattenedmerged = [item for sublist in merged for item in sublist]\n",
    "flattenedmerged\n",
    "print(flattenedmerged)\n",
    "X,y = getXYdata(flattenedmerged, mode = 'thickness',rootpath = basepath,normmode = 'EQ-hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eede387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQUIVALENTLY \n",
    "X,y = getBalancedXYData(mode = 'thickness',normmode = 'EQ-hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002bce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the recall scores: [0.3572546  0.71035518 0.81283644 0.65528808 0.28542688 0.45091138]\n",
      "Here are the precisions scores: [0.43263083 0.15858834 0.39049135 0.34753035 0.44553484 0.44077169]\n",
      "Here are the accuracies scores: [0.82381572 0.7484809  0.78199405 0.75254216 0.73623512 0.7234933 ]\n",
      "Here are the f1 scores: [0.39134626 0.25928969 0.52754636 0.4541849  0.34794605 0.44578388]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6, shuffle=False)\n",
    "\n",
    "scores = score_model(GaussianNB,X,y, cv=kf)\n",
    "print(f'Here are the recall scores: {scores[::4]}')\n",
    "print(f'Here are the precisions scores: {scores[1::4]}')\n",
    "print(f'Here are the accuracies scores: {scores[2::4]}')\n",
    "print(f'Here are the f1 scores: {scores[3::4]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
