{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coregistration:\n",
    "* read images oct and maia and put them to gray scale\n",
    "* rescaled according to a magic numbers (30,36) va? to obtain px_per_va\n",
    "* computation of the cropping edge on each side to crop maia img \n",
    "* cropping on all sides of maia then reshape to OCT shape\n",
    "* preprocessing... stable min-max normalization of the img avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_oct = rgb2gray(io.imread('../data/oct.tif'))\n",
    "img_maia = rgb2gray(io.imread('../data/maia.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_oct = 30\n",
    "va_maia = 36\n",
    "oct_px_per_va = img_oct.shape[0] / va_oct\n",
    "maia_px_per_va = img_maia.shape[0] / va_maia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"OCT: {oct_px_per_va:.2f} px for 1 deg. | MAIA: {maia_px_per_va:.2f} for 1 deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = (va_maia - va_oct) / 2 * maia_px_per_va\n",
    "rounded_crop = int(crop)\n",
    "print(f\"Cropping each side by {crop:.2f} (rounded: {rounded_crop})\")\n",
    "y, x = img_maia.shape\n",
    "img_maia_cropped = img_maia[rounded_crop:(y - rounded_crop), rounded_crop:(x - rounded_crop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_maia_resized = resize(img_maia_cropped, img_oct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlayed = 0.5 * img_oct + 0.5 * img_maia_resized\n",
    "overlayed_boosted_contrast = np.uint8((overlayed - overlayed.min()) / (overlayed.max() - overlayed.min() + 1e-6) * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_maia_resized.min(), img_maia_resized.max())\n",
    "print(img_oct.min(), img_oct.max())\n",
    "print(overlayed_boosted_contrast.min(), overlayed_boosted_contrast.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave('../output/overlayed.png', overlayed_boosted_contrast)\n",
    "io.imsave('../output/maia_cropped.png', np.uint8(img_maia_resized * 255))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
